{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j_3D_w9t_RIj",
        "outputId": "01fb3908-ed81-4322-a903-33ed00fda864"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "from google.colab import files\n",
        "\n",
        "chukyo = pd.read_csv('/content/drive/MyDrive/IntegratedDB_DoNotTouch/Chukyo.csv')\n",
        "higas = pd.read_csv('/content/drive/MyDrive/IntegratedDB_DoNotTouch/Higashisurugawan.csv')\n",
        "kyushu = pd.read_csv('/content/drive/MyDrive/IntegratedDB_DoNotTouch/Kyushu.csv')\n",
        "tokyo = pd.read_csv('/content/drive/MyDrive/IntegratedDB_DoNotTouch/Tokyo.csv')\n",
        "sample_s = pd.read_csv('/content/drive/MyDrive/IntegratedDB_DoNotTouch/sample_submission.csv')\n",
        "data_s = pd.read_csv('/content/drive/MyDrive/IntegratedDB_DoNotTouch/Data_Specification.csv')\n",
        "test_f = pd.read_csv('/content/drive/MyDrive/IntegratedDB_DoNotTouch/test.csv')\n",
        "chukyo_zone_features = pd.read_csv('/content/drive/MyDrive/IntegratedDB_DoNotTouch/Chukyo_zone_feature_area.csv')\n",
        "higas_zone_features = pd.read_csv('/content/drive/MyDrive/IntegratedDB_DoNotTouch/Higashisurugawan_zone_feature_area.csv')\n",
        "kyushu_zone_features = pd.read_csv('/content/drive/MyDrive/IntegratedDB_DoNotTouch/Kyushu_zone_feature_area.csv')\n",
        "tokyo_zone_features = pd.read_csv('/content/drive/MyDrive/IntegratedDB_DoNotTouch/Tokyo_zone_feature_area.csv')\n",
        "kinki_zone_features = pd.read_csv('/content/drive/MyDrive/IntegratedDB_DoNotTouch/Kinki_zone_feature_area.csv')\n",
        "\n",
        "chukyo_copy = chukyo.copy()\n",
        "higas_copy = higas.copy()\n",
        "kyushu_copy = kyushu.copy()\n",
        "tokyo_copy = tokyo.copy()\n",
        "sample_copy = sample_s.copy()\n",
        "data_copy = data_s.copy()\n",
        "test_copy = test_f.copy()\n",
        "chukyo_zone_features_copy = chukyo_zone_features.copy()\n",
        "higas_zone_features_copy = higas_zone_features.copy()\n",
        "kyushu_zone_features_copy = kyushu_zone_features.copy()\n",
        "tokyo_zone_features_copy = tokyo_zone_features.copy()\n",
        "kinki_zone_features_copy = kinki_zone_features.copy()\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "df = pd.DataFrame(data_copy)\n",
        "\n",
        "cities = ['Tokyo', 'Chukyo']\n",
        "labels = ['Occupation', 'Trip Type']\n",
        "\n",
        "tokyo_occupation = df[(df['City'] == cities[0]) & (df['Type'] == labels[0])]\n",
        "tokyo_trip = df[(df['City'] == cities[0]) & (df['Type'] == labels[1])]\n",
        "\n",
        "chukyo_occupation = df[(df['City'] == cities[1]) & (df['Type'] == labels[0])]\n",
        "chukyo_trip = df[(df['City'] == cities[1]) & (df['Type'] == labels[1])]\n",
        "\n",
        "occupation = df[(df['Type'] == labels[0])]\n",
        "trip = df[(df['Type'] == labels[1])]\n",
        "\n",
        "# Get unique values in the 'Category' column and assign unique integers\n",
        "occupation['Occupation_Encoded'] = pd.factorize(occupation['Description'])[0]\n",
        "trip['Trip_Encoded'] = pd.factorize(trip['Description'])[0]\n",
        "\n",
        "occupation = occupation.drop('City', axis=1)\n",
        "occupation = occupation.drop('Type', axis=1)\n",
        "occupation = occupation.drop('Code', axis=1)\n",
        "\n",
        "trip = trip.drop('Code', axis=1)\n",
        "trip = trip.drop('City', axis=1)\n",
        "trip = trip.drop('Type', axis=1)\n",
        "\n",
        "tokyo_occupation.rename(columns={'Code': 'Occupation'}, inplace=True)\n",
        "tokyo_trip.rename(columns={'Code': 'Trip_type'}, inplace=True)\n",
        "\n",
        "chukyo_occupation.rename(columns={'Code': 'Occupation'}, inplace=True)\n",
        "chukyo_trip.rename(columns={'Code': 'Trip_type'}, inplace=True)\n",
        "\n",
        "# Convert to int\n",
        "tokyo_copy['Occupation'] = tokyo_copy['Occupation'].astype(int)\n",
        "chukyo_copy['Occupation'] = chukyo_copy['Occupation'].astype(int)\n",
        "\n",
        "tokyo_copy['Trip_type'] = tokyo_copy['Trip_type'].astype(int)\n",
        "chukyo_copy['Trip_type'] = chukyo_copy['Trip_type'].astype(int)\n",
        "\n",
        "tokyo_occupation['Occupation'] = tokyo_occupation['Occupation'].astype(int)\n",
        "chukyo_occupation['Occupation'] = chukyo_occupation['Occupation'].astype(int)\n",
        "\n",
        "tokyo_trip['Trip_type'] = tokyo_trip['Trip_type'].astype(int)\n",
        "chukyo_trip['Trip_type'] = chukyo_trip['Trip_type'].astype(int)\n",
        "\n",
        "tokyo_modified = pd.merge(tokyo_copy, tokyo_occupation, on='Occupation', how='inner')\n",
        "tokyo_modified = tokyo_modified.drop('Occupation', axis=1)\n",
        "tokyo_modified = tokyo_modified.drop('Type', axis=1)\n",
        "tokyo_modified = tokyo_modified.drop('City', axis=1)\n",
        "tokyo_modified.rename(columns={'Description': 'Occupation'}, inplace=True)\n",
        "\n",
        "chukyo_modified = pd.merge(chukyo_copy, chukyo_occupation, on='Occupation', how='inner')\n",
        "chukyo_modified = chukyo_modified.drop('Occupation', axis=1)\n",
        "chukyo_modified = chukyo_modified.drop('Type', axis=1)\n",
        "chukyo_modified = chukyo_modified.drop('City', axis=1)\n",
        "chukyo_modified.rename(columns={'Description': 'Occupation'}, inplace=True)\n",
        "\n",
        "tokyo_modified = pd.merge(tokyo_modified, tokyo_trip, on='Trip_type', how='inner')\n",
        "tokyo_modified = tokyo_modified.drop('Trip_type', axis=1)\n",
        "tokyo_modified.rename(columns={'Description': 'Trip_type'}, inplace=True)\n",
        "tokyo_modified = tokyo_modified.drop('Type', axis=1)\n",
        "\n",
        "chukyo_modified = pd.merge(chukyo_modified, chukyo_trip, on='Trip_type', how='inner')\n",
        "chukyo_modified = chukyo_modified.drop('Trip_type', axis=1)\n",
        "chukyo_modified.rename(columns={'Description': 'Trip_type'}, inplace=True)\n",
        "chukyo_modified = chukyo_modified.drop('Type', axis=1)\n",
        "\n",
        "tokyo_features = tokyo_zone_features_copy.rename(columns={'ZONE_ID': 'Origin'})\n",
        "chukyo_features = chukyo_zone_features_copy.rename(columns={'ZONE_ID': 'Origin'})\n",
        "\n",
        "tokyo_modified = pd.merge(tokyo_modified, tokyo_features, on='Origin', how='inner')\n",
        "chukyo_modified = pd.merge(chukyo_modified, chukyo_features, on='Origin', how='inner')\n",
        "\n",
        "tokyo_modified.rename(columns={'T000918002': 'Number of business establishments (secondary sector of industry)', 'T000918006' : 'Number of employees (secondary sector of industry)', 'T000918021' : 'Number of business establishments (tertiary sector of industry)', 'T000918025' : 'Number of employees (tertiary sector of industry)', 'T000847001' : 'Night Population' }, inplace=True)\n",
        "chukyo_modified.rename(columns={'T000918002': 'Number of business establishments (secondary sector of industry)', 'T000918006' : 'Number of employees (secondary sector of industry)', 'T000918021' : 'Number of business establishments (tertiary sector of industry)', 'T000918025' : 'Number of employees (tertiary sector of industry)', 'T000847001' : 'Night Population' }, inplace=True)\n",
        "\n",
        "occupation_rename = occupation.rename(columns={'Description': 'Occupation'})\n",
        "\n",
        "tokyo_modified = pd.merge(tokyo_modified, occupation_rename, on='Occupation', how='inner')\n",
        "chukyo_modified = pd.merge(chukyo_modified, occupation_rename, on='Occupation', how='inner')\n",
        "\n",
        "trip_rename = trip.rename(columns={'Description': 'Trip_type'})\n",
        "\n",
        "tokyo_modified = pd.merge(tokyo_modified, trip_rename, on='Trip_type', how='inner')\n",
        "chukyo_modified = pd.merge(chukyo_modified, trip_rename, on='Trip_type', how='inner')\n",
        "\n",
        "chukyo_modified = chukyo_modified.drop_duplicates()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i3VqsFANWYUd"
      },
      "source": [
        "*Reading Files from the drive and creating a copy of each DS*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tk69mM7wDhad"
      },
      "outputs": [],
      "source": [
        "#reading the text file\n",
        "data_path = '/content/drive/MyDrive/IntegratedDB_DoNotTouch/feature_description.txt'\n",
        "\n",
        "with open(data_path) as fid:\n",
        "    data = \"Dummy String\"\n",
        "    while data:\n",
        "        data = fid.readline()\n",
        "        # print(data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R6M1wOZa4cD2"
      },
      "outputs": [],
      "source": [
        "chukyo_zone_features_copy['Destination_New'] =  range(0, 1009)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-UzXZOcb5HqO",
        "outputId": "ebd17fdf-030c-4e2f-bfa9-c3dba84cdb3e"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-6-70193c7c7148>:2: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  czp.rename(columns={'ZONE_ID': 'Destination'}, inplace=True)\n"
          ]
        }
      ],
      "source": [
        "czp = chukyo_zone_features_copy[['Destination_New', 'ZONE_ID']]\n",
        "czp.rename(columns={'ZONE_ID': 'Destination'}, inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AB79Uf5sVnan"
      },
      "outputs": [],
      "source": [
        "czp =czp.drop_duplicates()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2YulUJJt46CB",
        "outputId": "b44c174c-ea85-4644-d07e-5430edf5c77a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "205435"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "chukyo_modified = pd.merge(chukyo_modified, czp, on='Destination', how='inner')\n",
        "len(chukyo_modified)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jqy0H4W1L3u0"
      },
      "outputs": [],
      "source": [
        "chukyo_modified['Departure_time'] = pd.to_datetime(chukyo_modified['Departure_time'])\n",
        "chukyo_modified['Departure_time'] = chukyo_modified['Departure_time'].dt.time"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F64uVTmgQewN"
      },
      "outputs": [],
      "source": [
        "chukyo_modified = chukyo_modified.sort_values(by='Departure_time', ascending=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PFYtoMqAOAKm"
      },
      "outputs": [],
      "source": [
        "# Convert the 'TimeOnly' column to a string with a custom format\n",
        "chukyo_modified['Departure_time'] = chukyo_modified['Departure_time'].apply(lambda x: x.strftime('%H'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "irziV5d822FX"
      },
      "outputs": [],
      "source": [
        "# Creating training and testing sets.\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "chukyo_df = pd.DataFrame(chukyo_modified)\n",
        "\n",
        "# X = pd.DataFrame(data.data, columns=data.feature_names)\n",
        "# y = (data.target == 0).astype(int)  # Binary classification: Setosa vs. Not Setosa\n",
        "result = chukyo_df['Destination_New'].values\n",
        "input = chukyo_df.drop('Destination_New', axis=1, inplace=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E_UxtmdpdOId"
      },
      "outputs": [],
      "source": [
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(chukyo_df, result, test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FeUI5uJq_X27"
      },
      "source": [
        "Feature Engineering."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-JlWCvSW6NeL"
      },
      "outputs": [],
      "source": [
        "x_train_dropped = X_train.drop(['Occupation', 'City', 'Trip_type', 'Destination', 'Destination_New'], axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EsewdxTg41_i",
        "outputId": "9cc3351f-4f3e-4367-dde3-c1746e1d9eda"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Selected features using Univariate Feature Selection: [0 4 5 6 9]\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.feature_selection import SelectKBest, chi2, f_classif, RFE\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.feature_selection import SelectFromModel\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.feature_selection import mutual_info_classif\n",
        "\n",
        "# 1. Correlation Analysis\n",
        "# correlation_matrix = np.corrcoef(x_train_dropped, rowvar=False)\n",
        "# highly_correlated_features = np.where(np.abs(correlation_matrix) > 0.8)\n",
        "\n",
        "# 2. Univariate Feature Selection\n",
        "k_best = 5  # You can adjust this based on the number of features you want to select\n",
        "selector = SelectKBest(score_func=f_classif, k=k_best)\n",
        "X_train_univariate = selector.fit_transform(x_train_dropped, y_train)\n",
        "selected_features_univariate = np.where(selector.get_support())[0]\n",
        "print(\"Selected features using Univariate Feature Selection:\", selected_features_univariate)\n",
        "\n",
        "# 3. Recursive Feature Elimination (RFE)\n",
        "model = RandomForestClassifier(n_estimators=10)\n",
        "rfe_selector = RFE(model, n_features_to_select=k_best)\n",
        "X_train_rfe = rfe_selector.fit_transform(x_train_dropped, y_train)\n",
        "selected_features_rfe = np.where(rfe_selector.support_)[0]\n",
        "print(\"Selected features using Recursive Feature Elimination (RFE):\", selected_features_rfe)\n",
        "\n",
        "# 4. Tree-based Methods\n",
        "tree_model = RandomForestClassifier(n_estimators=10)\n",
        "tree_model.fit(x_train_dropped, y_train)\n",
        "importances = tree_model.feature_importances_\n",
        "selected_features_tree = np.argsort(importances)[-k_best:]\n",
        "print(\"Selected features using Tree-based Methods:\", selected_features_tree)\n",
        "\n",
        "# # 6. Principal Component Analysis (PCA)\n",
        "# pca = PCA(n_components=k_best)\n",
        "# X_train_pca = pca.fit_transform(x_train_dropped)\n",
        "# selected_features_pca = pca.components_.argsort()[:, -k_best:]\n",
        "# print(\"Selected features using Principal Component Analysis (PCA):\", selected_features_pca)\n",
        "\n",
        "from sklearn.feature_selection import mutual_info_classif\n",
        "# 7. Information Gain and Entropy (SelectKBest with mutual_info_classif)\n",
        "selector_info_gain = SelectKBest(score_func=mutual_info_classif, k=k_best)\n",
        "X_train_info_gain = selector_info_gain.fit_transform(x_train_dropped, y_train)\n",
        "selected_features_info_gain = np.where(selector_info_gain.get_support())[0]\n",
        "\n",
        "# 8. Feature Importance from Embedded Methods (SelectFromModel)\n",
        "embed_model = DecisionTreeClassifier()\n",
        "embed_selector = SelectFromModel(embed_model)\n",
        "X_train_embed = embed_selector.fit_transform(x_train_dropped, y_train)\n",
        "selected_features_embed = np.where(embed_selector.get_support())[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TnrVt5mM7LFz"
      },
      "outputs": [],
      "source": [
        "# Display selected features for each method\n",
        "# print(\"Selected features using Correlation Analysis:\", highly_correlated_features)\n",
        "print(\"Univariate Feature Selection:\\n\", selected_features_univariate)\n",
        "print(\"Recursive Feature Elimination (RFE):\\n\", selected_features_rfe)\n",
        "print(\"Tree-based Methods:\\n\", selected_features_tree)\n",
        "# print(\"LASSO Regression:\", selected_features_lasso)\n",
        "print(\"Principal Component Analysis (PCA): \\n\", selected_features_pca)\n",
        "print(\"Information Gain and Entropy:\\n\", selected_features_info_gain)\n",
        "print(\"Feature Importance from Embedded Methods:\\n\", selected_features_embed)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0iX6IK9LSNeD"
      },
      "outputs": [],
      "source": [
        "x_train_dropped"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LpZ-CL75OiPE",
        "outputId": "845cbbc2-61f1-4058-c804-b3ab4d2ace63"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Selected features using Univariate Feature Selection: ['Pid', 'Origin', 'Number of business establishments (secondary sector of industry)', 'Number of business establishments (tertiary sector of industry)', 'Number of employees (tertiary sector of industry)']\n",
            "Selected features using Recursive Feature Elimination (RFE): ['Number of business establishments (secondary sector of industry)', 'Number of employees (secondary sector of industry)', 'Number of business establishments (tertiary sector of industry)', 'Number of employees (tertiary sector of industry)', 'Night Population']\n",
            "Selected features using Tree-based Methods: ['Night Population', 'Number of business establishments (secondary sector of industry)', 'Number of employees (secondary sector of industry)', 'Number of business establishments (tertiary sector of industry)', 'Number of employees (tertiary sector of industry)']\n",
            "Selected features using Principal Component Analysis (PCA): ['Number of employees (secondary sector of industry)', 'Number of business establishments (tertiary sector of industry)', 'Night Population', 'Number of employees (tertiary sector of industry)', 'Pid']\n",
            "Selected features using Information Gain and Entropy: ['Number of business establishments (secondary sector of industry)', 'Number of employees (secondary sector of industry)', 'Number of business establishments (tertiary sector of industry)', 'Number of employees (tertiary sector of industry)', 'Night Population']\n",
            "Selected features using Feature Importance from Embedded Methods: ['Number of business establishments (secondary sector of industry)', 'Number of employees (secondary sector of industry)', 'Number of business establishments (tertiary sector of industry)', 'Number of employees (tertiary sector of industry)', 'Night Population']\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "\n",
        "# Get feature names from DataFrame columns\n",
        "feature_names = x_train_dropped.columns\n",
        "\n",
        "# Display selected features for each method with names\n",
        "def print_selected_features(method_name, selected_indices):\n",
        "    valid_indices = [i for i in selected_indices if i < len(feature_names)]\n",
        "    selected_feature_names = [feature_names[i] for i in valid_indices]\n",
        "    print(f\"Selected features using {method_name}: {selected_feature_names}\")\n",
        "\n",
        "# Call the function for each method\n",
        "# print_selected_features(\"Correlation Analysis\", highly_correlated_features[0] if len(highly_correlated_features) > 0 else [])\n",
        "print_selected_features(\"Univariate Feature Selection\", selected_features_univariate)\n",
        "print_selected_features(\"Recursive Feature Elimination (RFE)\", selected_features_rfe)\n",
        "print_selected_features(\"Tree-based Methods\", selected_features_tree)\n",
        "# print_selected_features(\"LASSO Regression\", selected_features_lasso)\n",
        "print_selected_features(\"Principal Component Analysis (PCA)\", selected_features_pca[0] if len(selected_features_pca) > 0 else [])\n",
        "print_selected_features(\"Information Gain and Entropy\", selected_features_info_gain)\n",
        "print_selected_features(\"Feature Importance from Embedded Methods\", selected_features_embed)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jupBIvniATOp"
      },
      "source": [
        "Cross-validation is a technique used to assess how well a model will generalize to an independent dataset. It helps to ensure that your model is not overfitting to the training data. Here's a general outline of how you can use cross-validation in combination with feature selection and model training:\n",
        "\n",
        "You can adapt this template to use different classifiers, feature selection methods, and evaluation metrics based on your specific needs. Keep in mind that the number of features selected (n_features_to_select in the example) and other hyperparameters should be fine-tuned based on the characteristics of your dataset.\n",
        "\n",
        "Remember to replace the RandomForestClassifier and RFE with the classifier and feature selection method you find most suitable for your problem. Adjust the number of splits in the cross-validation (n_splits) based on the size of your dataset.\n",
        "\n",
        "This will give you an array of accuracy scores for each fold, as well as the mean accuracy across all folds."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1AuDdjBW3CPe"
      },
      "outputs": [],
      "source": [
        "# from sklearn.model_selection import cross_val_score, StratifiedKFold\n",
        "# from sklearn.ensemble import RandomForestClassifier\n",
        "# from sklearn.feature_selection import RFE\n",
        "\n",
        "# # use the model that you finalize\n",
        "# model = RandomForestClassifier()\n",
        "# rfe = RFE(model, n_features_to_select=5)\n",
        "\n",
        "# # Assuming X is your feature matrix and y is your target variable\n",
        "\n",
        "# # Feature selection using RFE\n",
        "# X_selected = rfe.fit_transform(x_train_dropped, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "St65fvPzUlI7"
      },
      "outputs": [],
      "source": [
        "X_selected = x_train_dropped.iloc[:, [5, 6, 7, 8, 9]]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G4x8yg0lAU05",
        "outputId": "8ac80845-3d6d-41b4-afe5-8da3030675d9"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_split.py:700: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cross-Validation Scores: [1.         0.99996958 0.99993915 1.         1.        ]\n",
            "Mean Accuracy: 0.9999817462731974\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import cross_val_score, StratifiedKFold\n",
        "\n",
        "# Initialize cross-validation\n",
        "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "# Perform cross-validation with the selected features\n",
        "scores = cross_val_score(model, X_selected, y_train, cv=cv, scoring='accuracy')\n",
        "\n",
        "print(\"Cross-Validation Scores:\", scores)\n",
        "print(\"Mean Accuracy:\", scores.mean())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5hStrbgIONFI"
      },
      "outputs": [],
      "source": [
        "# Create and train an XGBoost classifier for multiclass classification\n",
        "import xgboost as xgb\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "le = LabelEncoder()\n",
        "y_train = le.fit_transform(y_train)\n",
        "X_train['Departure_time'] = le.fit_transform(X_train['Departure_time'].astype(str))\n",
        "X_train['Occupation'] = le.fit_transform(X_train['Occupation'].astype(str))\n",
        "X_train['City'] = le.fit_transform(X_train['City'].astype(str))\n",
        "X_train['Trip_type'] = le.fit_transform(X_train['Trip_type'].astype(str))\n",
        "model = xgb.XGBClassifier(objective=\"multi:softprob\", num_class=1006)  # \"multi:softprob\" for multiclass\n",
        "model.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GsJ4aZvdUTT8"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# Make predictions on the test set\n",
        "X_test['Departure_time'] = le.fit_transform(X_test['Departure_time'].astype(str))\n",
        "X_test['Occupation'] = le.fit_transform(X_test['Occupation'].astype(str))\n",
        "X_test['City'] = le.fit_transform(X_test['City'].astype(str))\n",
        "X_test['Trip_type'] = le.fit_transform(X_test['Trip_type'].astype(str))\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Calculate accuracy\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(\"Accuracy:\", accuracy)\n",
        "\n",
        "# Generate a classification report\n",
        "\n",
        "# class_names = data.target_names\n",
        "report = classification_report(y_test, y_pred)\n",
        "print(\"Classification Report:\\n\", report)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g9Ta1GzP5tpk",
        "outputId": "8a2fef26-48fc-4ed4-dc9d-b8e173c4b770"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mean Squared Error: 118272.18132255945\n",
            "Root Mean Squared Error: 343.9072277847028\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import mean_squared_error\n",
        "import numpy as np\n",
        "\n",
        "# Calculate mean squared error\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "\n",
        "# Calculate root mean squared error\n",
        "rmse = np.sqrt(mse)\n",
        "\n",
        "print(\"Mean Squared Error:\", mse)\n",
        "print(\"Root Mean Squared Error:\", rmse)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hV4HGU0I6Rr0",
        "outputId": "55901a9f-d877-4385-8f27-1b5ecfe6bcee"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy: 0.25\n",
            "Precision: 0.93\n",
            "Recall: 0.25\n",
            "F1 Score: 0.21\n",
            "Confusion Matrix:\n",
            "[[0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]\n",
            " ...\n",
            " [0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]]\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report, confusion_matrix\n",
        "\n",
        "\n",
        "# Calculate accuracy\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f'Accuracy: {accuracy:.2f}')\n",
        "\n",
        "# Calculate precision\n",
        "precision = precision_score(y_test, y_pred, average='weighted', zero_division=1)\n",
        "print(f'Precision: {precision:.2f}')\n",
        "\n",
        "# Calculate recall\n",
        "recall = recall_score(y_test, y_pred, average='weighted', zero_division=1)\n",
        "print(f'Recall: {recall:.2f}')\n",
        "\n",
        "# Calculate F1 score\n",
        "f1 = f1_score(y_test, y_pred, average='weighted', zero_division=1)\n",
        "print(f'F1 Score: {f1:.2f}')\n",
        "\n",
        "# Display classification report\n",
        "# print('Classification Report:')\n",
        "# print(classification_report(y_test, y_pred))\n",
        "\n",
        "# Display confusion matrix\n",
        "conf_matrix = confusion_matrix(y_test, y_pred)\n",
        "print('Confusion Matrix:')\n",
        "print(conf_matrix)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VCPey4fnJErv"
      },
      "outputs": [],
      "source": [
        "# FOR REFERENCE OF HYPER PARAMETER TUNNING.\n",
        "\n",
        "import xgboost as xgb\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "# Define the parameter grid for grid search\n",
        "param_grid = {\n",
        "    'learning_rate': [0.01, 0.1, 0.3],\n",
        "    'n_estimators': [100, 200, 300],\n",
        "    'max_depth': [3, 4, 5],\n",
        "    'min_child_weight': [1, 2, 3],\n",
        "    'gamma': [0, 0.1, 0.2],\n",
        "    'subsample': [0.8, 0.9, 1.0],\n",
        "    'colsample_bytree': [0.8, 0.9, 1.0]\n",
        "}\n",
        "\n",
        "\n",
        "# Create an XGBoost classifier\n",
        "model = xgb.XGBClassifier(objective=\"multi:softprob\", num_class=1009)\n",
        "\n",
        "# Perform grid search with cross-validation\n",
        "grid_search = GridSearchCV(estimator=model, param_grid=param_grid, cv=3, n_jobs=5, verbose=1)\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "# Get the best hyperparameters\n",
        "best_params = grid_search.best_params_\n",
        "print(\"Best Hyperparameters:\", best_params)\n",
        "\n",
        "# Train a model with the best hyperparameters\n",
        "best_model = xgb.XGBClassifier(objective=\"multi:softprob\", num_class=3, **best_params)\n",
        "best_model.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions and evaluate the model\n",
        "y_pred = best_model.predict(X_test)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(\"Accuracy with Best Hyperparameters:\", accuracy)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RSaijBOG33or"
      },
      "outputs": [],
      "source": [
        "# Import the necessary libraries\n",
        "import xgboost as xgb\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "# Load the Iris dataset\n",
        "data = load_iris()\n",
        "X = pd.DataFrame(data.data, columns=data.feature_names)\n",
        "y = data.target  # Multiclass classification\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Create and train an XGBoost classifier for multiclass classification\n",
        "model = xgb.XGBClassifier(objective=\"multi:softprob\", num_class=3)  # \"multi:softprob\" for multiclass\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Calculate accuracy\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(\"Accuracy:\", accuracy)\n",
        "\n",
        "# Generate a classification report\n",
        "class_names = data.target_names\n",
        "report = classification_report(y_test, y_pred, target_names=class_names)\n",
        "print(\"Classification Report:\\n\", report)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qd-0Bk7W4DUM"
      },
      "outputs": [],
      "source": [
        "y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2hC9KSA6xLdh"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Create scatter plots for three pairs of features\n",
        "plt.figure(figsize=(12, 6))\n",
        "\n",
        "headval = 500000\n",
        "\n",
        "plt.subplot(1, 3, 1)\n",
        "plt.title(\"Chukyo City\\nDeparture Time vs Night Population\")\n",
        "sns.scatterplot(data=chukyo_modified.head(headval), x=\"Departure_time\", y=\"Night Population\", hue=\"Destination\")\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K7eO4ayYT6Ja"
      },
      "outputs": [],
      "source": [
        "plt.subplot(1, 2, 1)\n",
        "plt.title(\"Tokyo City\\nDeparture Time vs Night Population\")\n",
        "sns.scatterplot(data=tokyo_modified.head(headval), x=\"Departure_time\", y=\"Night Population\", hue=\"Destination\")\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f_d86nu23Q8n"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Create scatter plots for three pairs of features\n",
        "plt.figure(figsize=(12, 6))\n",
        "\n",
        "headval = 500000\n",
        "\n",
        "plt.subplot(1, 3, 1)\n",
        "sns.scatterplot(data=tokyo_modified.head(headval), x=\"Age\", y=\"Trip_Encoded\", hue=\"Destination\")\n",
        "plt.title(\"Occupation vs Night Population\")\n",
        "\n",
        "\n",
        "plt.subplot(1, 3, 2)\n",
        "sns.scatterplot(data=tokyo_modified.head(headval), x=\"Age\", y=\"Night Population\", hue=\"Destination\")\n",
        "plt.title(\"Age vs Night Population\")\n",
        "\n",
        "\n",
        "plt.subplot(1, 3, 3)\n",
        "sns.scatterplot(data=tokyo_modified.head(headval), x=\"Gender\", y=\"Night Population\", hue=\"Destination\")\n",
        "plt.title(\"Gender vs Night Population\")\n",
        "\n",
        "# plt.tight_layout()\n",
        "\n",
        "# Show the plots\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Tn2RX1tRET8B"
      },
      "outputs": [],
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "\n",
        "plot_data = pd.DataFrame(chukyo_modified)\n",
        "plt.figure(figsize=(24, 12))\n",
        "\n",
        "# plt.subplot(1, 1, 1)\n",
        "bp = sns.histplot(x=\"Age\", y=\"Occupation\", data=plot_data)\n",
        "bp.set_xticklabels(bp.get_xticklabels(), rotation=45, ha=\"right\")\n",
        "# plt.title(\"Night Population Distribution by Trip Type at Hour 1\")\n",
        "plt.xlabel(\"Age\")\n",
        "plt.ylabel(\"Occupation\")\n",
        "\n",
        "plt.show()\n",
        "\n",
        "# plt.subplot(2, 1, 1)\n",
        "bp = sns.histplot(x=\"Departure_time\", y=\"Occupation\", data=chukyo_modified)\n",
        "# bp.set_xticklabels(bp.get_xticklabels(), rotation=45, ha=\"right\")\n",
        "plt.xlabel(\"Age\")\n",
        "plt.ylabel(\"Occupation\")\n",
        "plt.show()\n",
        "\n",
        "# plt.subplot(3, 1, 1)\n",
        "bp = sns.histplot(x=\"Departure_time\", y=\"Trip_type\", data=plot_data)\n",
        "# bp.set_xticklabels(bp.get_xticklabels(), rotation=45, ha=\"right\")\n",
        "plt.title(\"Night Population Distribution by Trip Type at Hour 1\")\n",
        "plt.xlabel(\"Departure_time\")\n",
        "plt.ylabel(\"Trip type\")\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_WZYyfnadi31"
      },
      "outputs": [],
      "source": [
        "temp = chukyo_modified.rename(columns={'Number of business establishments (secondary sector of industry)': 'No. of II sector business.'}, inplace=False)\n",
        "temp = temp.rename(columns={'Number of employees (secondary sector of industry)': 'Employees in II business'}, inplace=False)\n",
        "temp = temp.rename(columns={'Number of business establishments (tertiary sector of industry)': 'No. of III sector business.'}, inplace=False)\n",
        "temp = temp.rename(columns={'Number of employees (tertiary sector of industry)': 'Employees in III business'}, inplace=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f9o6FUU3k5gQ"
      },
      "outputs": [],
      "source": [
        "temp['Departure_time'] = pd.to_datetime(chukyo_modified['Departure_time'])\n",
        "\n",
        "\n",
        "temp['Departure_time'] = temp['Departure_time'].dt.hour\n",
        "\n",
        "# temp['Departure_time'] = temp['Departure_time'].dt.hour"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oDCY1UQDcfxb"
      },
      "outputs": [],
      "source": [
        "correlation_matrix1 = temp.corr()\n",
        "plt.title(\"Chukyo City\\n HeatMap of Correlation Matrix\")\n",
        "sns.heatmap(correlation_matrix1, annot=False, cmap=\"coolwarm\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
